# My_Own_Micrograd

You can see the colab notebook [here](https://colab.research.google.com/drive/1azRgZSXrYj0L3_bIfIheFhPZ04WEi74I?usp=sharing) .
This is inspired from Andrej Karpathy's first video of the Zero to Hero series. [here](https://www.youtube.com/watch?v=VMj-3S1tku0) is the link to the video
In this video he creates a neural network from scratch and trains it, also from scratch.

![image](https://github.com/SamyakMahajan/My_Own_Micrograd/assets/118765670/ca76cc1b-074c-4a6e-839d-d93400a48da0)

On a Test I did this was the data used<br>
![image](https://github.com/SamyakMahajan/My_Own_Micrograd/assets/118765670/ca256ea9-b512-40d2-a151-6e94c5cbd9ef)

My Neural Net Was Able To Predict like this:<br>
![image](https://github.com/SamyakMahajan/My_Own_Micrograd/assets/118765670/8cb1b8e0-67db-43d6-af8f-26ef04201b2e)

<br>
I love how beautifully he has presented in the video. 
I didn't even know about the basics of ML, yet from the video I was able to understand:
1. gradients
2. how gradients are calculated efficiently using Backpropagation
3. how these gradients can be used to reduce the total_loss
4. What a Neuron is and how to code it.
5. What a Layer is and how to code it.
6. What a MultiLayer Perceptron Neural Network is and how to code it.
7. How to use gradients to train the Neural Net
And also, I learnt a lot about python programming too, mainly how he was able to make simple a+b and a*b operations into a complete tree structure!

This is the Node structure that was used:
![image](https://github.com/SamyakMahajan/My_Own_Micrograd/assets/118765670/125f36ff-ddc8-4160-8ba1-bb5f8266dfdd)

